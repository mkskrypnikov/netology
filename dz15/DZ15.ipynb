{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции \"Основы веб-скрапинга и работы с API\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "from datetime import datetime as dt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1.\n",
    "Обязательная часть\n",
    "Будем парсить страницу со свежеми новостям на habr.com/ru/all/.\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: - - .\n",
    "\n",
    "Дополнительная часть (необязательная)\n",
    "Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.\n",
    "\n",
    "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.\n",
    "\n",
    "Итоговый датафрейм формировать со столбцами: - - - <текст статьи>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS = ['python', 'парсинг', 'php']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:07.097320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>url_news</th>\n",
       "      <th>title_news</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>php</td>\n",
       "      <td>https://habr.com/ru/post/522348/</td>\n",
       "      <td>\\nТипобезопасная работа с массивами PHP, часть...</td>\n",
       "      <td>[\\n, [\\n, [\\n, &lt;span class=\"default-image_mini...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword                          url_news  \\\n",
       "0     php  https://habr.com/ru/post/522348/   \n",
       "\n",
       "                                          title_news  \\\n",
       "0  \\nТипобезопасная работа с массивами PHP, часть...   \n",
       "\n",
       "                                                post  \n",
       "0  [\\n, [\\n, [\\n, <span class=\"default-image_mini...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = dt.now()\n",
    "dict_url = []\n",
    "news_filtr = []\n",
    "x = 1\n",
    "while x < 10:\n",
    "    url = 'https://habr.com/ru/all/page' + str(x)\n",
    "    response = requests.get(url, headers={'User-Agent': UserAgent().chrome})\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    posts = soup.find_all('article', class_='post')\n",
    "    for post in posts:\n",
    "        if 'сегодня' in post.find('span', {'class': 'post__time'}).text:\n",
    "            url_news = post.find('a', {'class': 'post__title_link'}).get('href')\n",
    "            dict_url.append(url_news)\n",
    "        else:\n",
    "            x = 10\n",
    "            break        \n",
    "    x += 1\n",
    "    time.sleep(0.3)\n",
    "dict_url\n",
    "for news in dict_url:\n",
    "    url = news\n",
    "    response = requests.get(url, headers={'User-Agent': UserAgent().chrome})\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    title = soup.find('h1', {'class' : 'post__title post__title_full'}).text\n",
    "    posts = soup.find('div', {'class' : 'post__body post__body_full'})   \n",
    "    for key in KEYWORDS:\n",
    "        if key in posts.text.lower().split():\n",
    "            news_filtr.append({'keyword': key, 'url_news' : url, 'title_news' : title, 'post' : post})\n",
    "        else:\n",
    "            continue\n",
    "    time.sleep(0.3)\n",
    "df_news = pd.DataFrame(news_filtr)\n",
    "print(dt.now() - start_time)  \n",
    "df_news\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.\n",
    "Обязательная часть\n",
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck. Список email-ов задаем переменной в начале кода:\n",
    "EMAIL = [xxx@x.ru, yyy@y.com]\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: - <дата утечки> - <источник утечки> - <описание утечки>.\n",
    "\n",
    "Подсказка: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL = ['xxx@x.ru', 'yyy@y.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>publishDate</th>\n",
       "      <th>site</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2019-03-28T00:00:00Z</td>\n",
       "      <td>verifications.io</td>\n",
       "      <td>Big data e-mail verification platform verifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2020-05-21T00:00:00Z</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>At some time in 2020, the Russian social netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>parapa.mail.ru</td>\n",
       "      <td>In July and August 2016, two criminals execute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2016-10-29T00:00:00Z</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>Popular Russian social networking platform VKo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      email           publishDate              site  \\\n",
       "0  xxx@x.ru  2019-03-28T00:00:00Z  verifications.io   \n",
       "1  xxx@x.ru  2020-05-21T00:00:00Z            vk.com   \n",
       "2  xxx@x.ru  2017-02-14T00:00:00Z    parapa.mail.ru   \n",
       "3  xxx@x.ru  2016-10-29T00:00:00Z            vk.com   \n",
       "4  xxx@x.ru  2016-10-21T00:00:00Z         adobe.com   \n",
       "\n",
       "                                         description  \n",
       "0  Big data e-mail verification platform verifica...  \n",
       "1  At some time in 2020, the Russian social netwo...  \n",
       "2  In July and August 2016, two criminals execute...  \n",
       "3  Popular Russian social networking platform VKo...  \n",
       "4  In October of 2013, criminals penetrated Adobe...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_avast = []\n",
    "for email in EMAIL:\n",
    "    url = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data?'\n",
    "    params = {\"emailAddresses\":[email]}\n",
    "    headers = {'Vaar-Version': '0',\n",
    "    'Vaar-Header-App-Product': 'hackcheck-web-avast'}\n",
    "    res = requests.post(url, data=json.dumps(params), headers = headers)\n",
    "    for x in res.json()['breaches']:\n",
    "        dict_avast.append({'email': email, 'publishDate': res.json()['breaches'][x]['publishDate'], 'site' : res.json()['breaches'][x]['site'], 'description' : res.json()['breaches'][x]['description']})\n",
    "    df_avast = pd.DataFrame(dict_avast)\n",
    "df_avast.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
